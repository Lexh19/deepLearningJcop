{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "sw_indo = stopwords.words('indonesian') + list(punctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jakarta Dikangkangi Para Preman\\nKALAU tak pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penyimpangan di Setpres Seolah Terjadi Sekaran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Kekerasan, Elite agar Duduk Bersama\\nSeju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                teks\n",
       "0  Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...\n",
       "1  Jakarta Dikangkangi Para Preman\\nKALAU tak pun...\n",
       "2  Penyimpangan di Setpres Seolah Terjadi Sekaran...\n",
       "3  Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...\n",
       "4  Stop Kekerasan, Elite agar Duduk Bersama\\nSeju..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data/kompas.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akmal\\anaconda3\\envs\\jcopdl\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\akmal\\anaconda3\\envs\\jcopdl\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer(ngram_range=(1, 2), tokenizer=word_tokenize, stop_words=sw_indo, min_df=5)\n",
    "bow_matrix = bow.fit_transform(df.teks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = bow.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25134"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(model):\n",
    "    return [[vocab[idx] for idx in reversed(comp.argsort()[-6:]) if vocab[idx].isalnum()] \n",
    "            for comp in model.components_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent semantic analysis (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=10, n_iter=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_matrix = lsa.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2008, 25134)\n",
      "(2008, 10)\n",
      "(10, 25134)\n"
     ]
    }
   ],
   "source": [
    "# analogi\n",
    "print(bow_matrix.shape) # hidden\n",
    "print(lsa_matrix.shape) # weight / code\n",
    "print(lsa.components_.shape) # fitur / topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['presiden', 'indonesia', 'pemerintah', 'dpr'],\n",
       " ['presiden', 'dpr', 'ketua', 'partai', 'mpr', 'tandjung'],\n",
       " ['pemerintah', 'rp', 'indonesia', 'bank', 'persen', 'utang'],\n",
       " ['presiden', 'indonesia', 'as', 'abdurrahman', 'wahid'],\n",
       " ['presiden', 'air', 'banjir', 'harga', 'rp', 'dpr'],\n",
       " ['harga', 'beras', 'rp', 'bbm'],\n",
       " ['mpr', 'konstitusi', 'bppn', 'uud'],\n",
       " ['indonesia', 'mpr', 'konstitusi', 'uud', 'perubahan', '1945'],\n",
       " ['pemerintah', 'dpr', 'israel', 'bppn', 'kota', 'aceh'],\n",
       " ['indonesia', 'pemerintah', 'dpr', 'beras', 'utang', 'air']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic(lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, max_iter=10, random_state=42)\n",
    "lda_matrix = lda.fit_transform(bow_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tandjung', 'dpr', 'hukum', 'ketua'],\n",
       " ['bank', 'indonesia', 'pemerintah', 'ekonomi'],\n",
       " ['pesawat', 'orang', 'rumah', 'korban'],\n",
       " ['banjir', 'air', 'warga', 'jakarta', 'jalan'],\n",
       " ['tni', 'hukum', 'ginandjar', 'tim'],\n",
       " ['rp', 'pemerintah', 'harga', 'bppn'],\n",
       " ['indonesia', 'as', 'pemerintah', 'aceh'],\n",
       " ['presiden', 'dpr', 'politik', 'ketua'],\n",
       " ['daerah', 'indonesia', 'masyarakat', 'maluku'],\n",
       " ['polisi', 'kepala', 'jakarta', 'orang']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_topic(lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
